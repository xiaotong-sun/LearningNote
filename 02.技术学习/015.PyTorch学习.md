# PyTorch学习



## nn模块

在PyTorch 中，`nn`模块包含了一些常用的神经网络层和函数。这些层和函数被设计成可以高效地运行在GPU上，并且能够自动计算反向传播梯度，从而方便地进行深度学习模型的训练。

`nn` 模块中包含的一些常见的层和函数包括：

- 线性层（`nn.Linear`）：实现线性变换（即仿射变换），常用于全连接层
- 卷积层（`nn.Conv2d`、`nn.ConvTranspose2d` 等）：实现卷积和逆卷积操作，常用于图像处理任务
- 池化层（`nn.MaxPool2d`、`nn.AvgPool2d` 等）：实现最大池化和平均池化操作，用于下采样特征图
- 激活函数（`nn.ReLU`、`nn.Sigmoid`、`nn.Tanh` 等）：实现各种激活函数，常用于增加模型的非线性能力
- 归一化层（`nn.BatchNorm2d`、`nn.LayerNorm` 等）：实现批量归一化、层归一化等归一化操作，帮助提高模型的稳定性和泛化能力
- 损失函数（`nn.CrossEntropyLoss`、`nn.MSELoss` 等）：实现各种损失函数，常用于训练和评估深度学习模型

总之，`nn` 模块中包含了许多常见的神经网络层和函数，使用它们可以极大地简化深度学习模型的设计和训练过程。